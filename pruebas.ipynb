{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rq_-jS9HtUU-"
      },
      "source": [
        "<img src=\"https://i.imgur.com/6U6q5jQ.png\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-cCaZ1r2tUVA"
      },
      "source": [
        "<a target=\"_blank\" href=\"https://colab.research.google.com/github/SocialAnalytics-StrategicIntelligence/GeoDFBasics_py/blob/main/index.ipynb\">\n",
        "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
        "</a>\n",
        "\n",
        "# The Geo Dataframe\n",
        "\n",
        "The geodataframe (GDF) is a dataframe (DF) where every row represents an spatial element (point, line, polygon).\n",
        "\n",
        "Historically, the most common file type that stores spatial elements is the shapefile. Let's take a look at some of them:\n",
        "\n",
        "1. In GitHub (cloud), create a repository named: introgeodf.\n",
        "2. Clone that repo to a local folder in your computer.\n",
        "3. In that local folder in your computer, create a folder named **maps**.\n",
        "4. Go to paidea and download three compressed files.\n",
        "5. Download those files into the folder **maps** in your computer: *countries*, *cities*, and *rivers*."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PhGJmen1tUVB"
      },
      "source": [
        "You may see something like this:\n",
        "\n",
        "<img src=\"https://github.com/CienciaDeDatosEspacial/code_and_data/blob/main/mapsFolderImage.png?raw=true\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HBs3ovRstUVB"
      },
      "source": [
        "You can decompress those files:\n",
        "\n",
        "<img title=\"a title\" alt=\"Alt text\" src=\"https://github.com/CienciaDeDatosEspacial/code_and_data/blob/main/folderRar_1.png?raw=true\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OzvFDa2JtUVB"
      },
      "source": [
        "Now, take a look a **World_Countries**:\n",
        "\n",
        "<img src=\"https://github.com/CienciaDeDatosEspacial/code_and_data/blob/main/imageCountries_shp.png?raw=true\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BUOIWMOTtUVB"
      },
      "source": [
        "There, you see that this **one map** requires **several files**. That is the nature of the shapefile.\n",
        "\n",
        "Let's read the file with the help of **geopandas**:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "KJV5G0POtUVB",
        "outputId": "e17c1a84-8d7e-4147-821e-8eacb70d20dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 918
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: geopandas in /usr/local/lib/python3.10/dist-packages (0.14.4)\n",
            "Requirement already satisfied: fiona>=1.8.21 in /usr/local/lib/python3.10/dist-packages (from geopandas) (1.10.0)\n",
            "Requirement already satisfied: numpy>=1.22 in /usr/local/lib/python3.10/dist-packages (from geopandas) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from geopandas) (24.1)\n",
            "Requirement already satisfied: pandas>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from geopandas) (2.1.4)\n",
            "Requirement already satisfied: pyproj>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from geopandas) (3.6.1)\n",
            "Requirement already satisfied: shapely>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from geopandas) (2.0.6)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.10/dist-packages (from fiona>=1.8.21->geopandas) (24.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from fiona>=1.8.21->geopandas) (2024.8.30)\n",
            "Requirement already satisfied: click~=8.0 in /usr/local/lib/python3.10/dist-packages (from fiona>=1.8.21->geopandas) (8.1.7)\n",
            "Requirement already satisfied: click-plugins>=1.0 in /usr/local/lib/python3.10/dist-packages (from fiona>=1.8.21->geopandas) (1.1.1)\n",
            "Requirement already satisfied: cligj>=0.5 in /usr/local/lib/python3.10/dist-packages (from fiona>=1.8.21->geopandas) (0.7.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.4.0->geopandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.4.0->geopandas) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.4.0->geopandas) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=1.4.0->geopandas) (1.16.0)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "DriverError",
          "evalue": "Failed to open dataset (flags=68): maps/World_Countries/World_Countries.shp",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mCPLE_OpenFailedError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32mfiona/ogrext.pyx\u001b[0m in \u001b[0;36mfiona.ogrext.gdal_open_vector\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mfiona/ogrext.pyx\u001b[0m in \u001b[0;36mfiona.ogrext.gdal_open_vector\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mfiona/_err.pyx\u001b[0m in \u001b[0;36mfiona._err.StackChecker.exc_wrap_pointer\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mCPLE_OpenFailedError\u001b[0m: maps/World_Countries/World_Countries.shp: No such file or directory",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mDriverError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-4034d0b7f7e1>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgeopandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mgpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mcountries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"maps\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"World_Countries\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"World_Countries.shp\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/geopandas/io/file.py\u001b[0m in \u001b[0;36m_read_file\u001b[0;34m(filename, bbox, mask, rows, engine, **kwargs)\u001b[0m\n\u001b[1;32m    287\u001b[0m             \u001b[0mpath_or_bytes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 289\u001b[0;31m         return _read_file_fiona(\n\u001b[0m\u001b[1;32m    290\u001b[0m             \u001b[0mpath_or_bytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrom_bytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbbox\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbbox\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrows\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/geopandas/io/file.py\u001b[0m in \u001b[0;36m_read_file_fiona\u001b[0;34m(path_or_bytes, from_bytes, bbox, mask, rows, where, **kwargs)\u001b[0m\n\u001b[1;32m    313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mfiona_env\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 315\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mreader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_bytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    316\u001b[0m             \u001b[0mcrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcrs_wkt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m             \u001b[0;31m# attempt to get EPSG code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/fiona/env.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0menv_ctor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/fiona/__init__.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode, driver, schema, crs, encoding, layer, vfs, enabled_drivers, crs_wkt, ignore_fields, ignore_geometry, include_fields, wkt_version, allow_unsupported_drivers, opener, **kwargs)\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"a\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m                 colxn = Collection(\n\u001b[0m\u001b[1;32m    343\u001b[0m                     \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m                     \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/fiona/collection.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path, mode, driver, schema, crs, encoding, layer, vsi, archive, enabled_drivers, crs_wkt, ignore_fields, ignore_geometry, include_fields, wkt_version, allow_unsupported_drivers, **kwargs)\u001b[0m\n\u001b[1;32m    224\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 226\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    227\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"a\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"w\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWritingSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mfiona/ogrext.pyx\u001b[0m in \u001b[0;36mfiona.ogrext.Session.start\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mfiona/ogrext.pyx\u001b[0m in \u001b[0;36mfiona.ogrext.gdal_open_vector\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mDriverError\u001b[0m: Failed to open dataset (flags=68): maps/World_Countries/World_Countries.shp"
          ]
        }
      ],
      "source": [
        "import os, geopandas as gpd\n",
        "\n",
        "countries=gpd.read_file(os.path.join(\"maps\",\"World_Countries\",\"World_Countries.shp\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a5AOj3mktUVC"
      },
      "source": [
        "Let's use some familiar DF functions:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BTVBGfNatUVC"
      },
      "outputs": [],
      "source": [
        "# what is it?\n",
        "type(countries)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AkvWskZytUVC"
      },
      "outputs": [],
      "source": [
        "# dimensions\n",
        "countries.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ETJdBBR1tUVD"
      },
      "outputs": [],
      "source": [
        "# names\n",
        "countries.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QrbZt4g5tUVD"
      },
      "outputs": [],
      "source": [
        "# some content\n",
        "countries.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vPHdGEtatUVD"
      },
      "outputs": [],
      "source": [
        "# any missing values?\n",
        "countries[countries.isna().any(axis=1)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TWXmBv-vtUVD",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# types\n",
        "countries.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QzT4ctrjtUVD"
      },
      "source": [
        "As you see, every pandas command is working, but now we have a new column type: **geometry**. Let's see this map of countries:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DjMj9myHtUVD"
      },
      "outputs": [],
      "source": [
        "countries.plot(facecolor=\"azure\",#color of polygon fill\n",
        "               edgecolor='black', #color of lines\n",
        "               linewidth=0.1) #thickness of lines"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iCtifGnqtUVD"
      },
      "source": [
        "Let's open the other maps:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lPbJ4wFHtUVD"
      },
      "outputs": [],
      "source": [
        "rivers=gpd.read_file(os.path.join(\"maps\",\"World_Hydrography\",\"World_Hydrography.shp\"))\n",
        "cities=gpd.read_file(os.path.join(\"maps\",\"World_Cities\",\"World_Cities.shp\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fG3jJoFu4T0V"
      },
      "source": [
        "This is the rivers map:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Gap_au4tUVD"
      },
      "outputs": [],
      "source": [
        "rivers.plot(edgecolor='blue',\n",
        "            linewidth=1,\n",
        "            linestyle='dotted')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9kpwszmv4T0V"
      },
      "source": [
        "This is the cities map:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8nAC2GkptUVD"
      },
      "outputs": [],
      "source": [
        "cities.plot(marker='.', # marker type\n",
        "            color='red',\n",
        "            markersize=1,\n",
        "            alpha=0.3) # transparency"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "prkK6IA8tUVE"
      },
      "source": [
        "You can plot all the layers, as long as they share the same projection.\n",
        "Let's verify that all have the same projection (**CRS**):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8G0MkpZ1tUVE"
      },
      "outputs": [],
      "source": [
        "countries.crs==cities.crs==cities.crs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZOiFM3uYtUVE"
      },
      "source": [
        "You can start by creating the layer on the back (the base), and add layers on top:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rqkVAvHstUVE"
      },
      "outputs": [],
      "source": [
        "base = countries.plot(facecolor=\"white\",\n",
        "                      edgecolor='black',\n",
        "                      linewidth=0.1,\n",
        "                      figsize=(12,12))\n",
        "\n",
        "rivers.plot(edgecolor='blue', linewidth=0.4,\n",
        "            ax=base)# on top of...\n",
        "cities.plot(marker='.', color='red', markersize=1,alpha=0.7,\n",
        "            ax=base) # on top of...\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QwW_EqUZ4T0W"
      },
      "outputs": [],
      "source": [
        "countries.to_file(os.path.join(\"maps\",\"worldMap.gpkg\"),layer='countryBorders', driver=\"GPKG\")\n",
        "rivers.to_file(os.path.join(\"maps\",\"worldMap.gpkg\"),layer='riverLines', driver=\"GPKG\")\n",
        "cities.to_file(os.path.join(\"maps\",\"worldMap.gpkg\"),layer='cityPoints', driver=\"GPKG\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4WVBq3bUtUVE"
      },
      "source": [
        "## Subsetting\n",
        "\n",
        "You can subset your map by *filtering*:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NsiI-8ZYtUVE"
      },
      "outputs": [],
      "source": [
        "brazil=countries[countries.COUNTRY=='Brazil']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "biux_VKutUVF"
      },
      "source": [
        "But you can also subset by *clipping*, as sometimes other data frames may not have the same fields for filtering:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ltxxI2OotUVF"
      },
      "outputs": [],
      "source": [
        "citiesBrazil_clipped = gpd.clip(gdf=cities,\n",
        "                          mask=brazil)\n",
        "riversBrazil_clipped = gpd.clip(gdf=rivers,\n",
        "                               mask=brazil)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2nXd5aiRtUVF"
      },
      "source": [
        "Then, you can plot the clipped version:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dEfKc5nQtUVF"
      },
      "outputs": [],
      "source": [
        "base = brazil.plot(facecolor=\"greenyellow\", edgecolor='black', linewidth=0.4,figsize=(5,5))\n",
        "citiesBrazil_clipped.plot(marker='+', color='red', markersize=15,\n",
        "                    ax=base)\n",
        "riversBrazil_clipped.plot(edgecolor='blue', linewidth=0.5,\n",
        "                    ax=base)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Z6aWKLN4T0W"
      },
      "source": [
        "You can also check what geometries you have in your GDF:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uE4UyFWN4T0W"
      },
      "outputs": [],
      "source": [
        "brazil.geom_type"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rG7MQw4S4T0X"
      },
      "outputs": [],
      "source": [
        "citiesBrazil_clipped.geom_type"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "n1MK519e4T0X"
      },
      "outputs": [],
      "source": [
        "riversBrazil_clipped.geom_type"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "teAyXtBw4T0X"
      },
      "source": [
        "Notice that the amount of elements (rows) is different, and that all those elements do not belong to the exact geometry type."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nSFxvDnR4T0X"
      },
      "source": [
        "<a class=\"anchor\" id=\"1\"></a>\n",
        "\n",
        "## Map Projection\n",
        "\n",
        "The CRS is a very important property of the maps. They affect three aspects:\n",
        "\n",
        "* shape\n",
        "* area\n",
        "* scale\n",
        "* direction\n",
        "\n",
        "Most maps come with a default CRS: 4326. Pay attention:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gptZOUuh4T0d"
      },
      "outputs": [],
      "source": [
        "# check units\n",
        "brazil.crs.axis_info"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SDDfCIMx4T0d"
      },
      "source": [
        "Polygons have a centroid. When we try getting a centroid from an **unprojected** polygon, you get:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CLgY4Q_E4T0d"
      },
      "outputs": [],
      "source": [
        "# centroid\n",
        "brazil.centroid"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OEiHr27v4T0d"
      },
      "source": [
        "### Reprojecting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tNNHM7xM4T0e"
      },
      "source": [
        "A projected CRS will have units in meters or feet (or similar). You can request a crs per country [here](https://epsg.io/?q=brazil+kind%3APROJCRS):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nD_YQbY_4T0e"
      },
      "outputs": [],
      "source": [
        "# recommended for Brazil (meters)\n",
        "brazil.to_crs(5641).crs.axis_info"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZAFJyzs_4T0e"
      },
      "outputs": [],
      "source": [
        "# now this works\n",
        "brazil.to_crs(5641).centroid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zUFIX4ch4T0e"
      },
      "outputs": [],
      "source": [
        "# replotting:\n",
        "\n",
        "base5641=brazil.to_crs(5641).plot()\n",
        "brazil.to_crs(5641).centroid.plot(color='red',ax=base5641)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XvesjHIb4T0e"
      },
      "source": [
        "Let's keep the projected version for all our maps:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H1wl-82b4T0e"
      },
      "outputs": [],
      "source": [
        "brazil_5641=brazil.to_crs(5641)\n",
        "\n",
        "cities_brazil_5641=citiesBrazil_clipped.to_crs(brazil_5641.crs)\n",
        "\n",
        "rivers_brazil_5641=riversBrazil_clipped.to_crs(brazil_5641.crs)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N5B_uahJ4T0e"
      },
      "outputs": [],
      "source": [
        "# saving\n",
        "import os\n",
        "\n",
        "brazil_5641.to_file(os.path.join(\"maps\",\"brazilMaps_5641.gpkg\"), layer='country', driver=\"GPKG\")\n",
        "cities_brazil_5641.to_file(os.path.join(\"maps\",\"brazilMaps_5641.gpkg\"), layer='cities', driver=\"GPKG\")\n",
        "rivers_brazil_5641.to_file(os.path.join(\"maps\",\"brazilMaps_5641.gpkg\"), layer='rivers', driver=\"GPKG\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q0YAE5i74T0e"
      },
      "outputs": [],
      "source": [
        "brazil_5641.centroid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z-FAJsGZ4T0e"
      },
      "outputs": [],
      "source": [
        "brazil_5641.centroid.to_file(os.path.join(\"maps\",\"brazilMaps_5641.gpkg\"), layer='centroid', driver=\"GPKG\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nqrKfBoM4T0e"
      },
      "source": [
        "<a class=\"anchor\" id=\"3\"></a>\n",
        "\n",
        "## Creating Spatial data\n",
        "\n",
        "You will get Lines and Polygons as maps for sure, but that may not be the case with points. Let me download a **CSV** file with information on the airports in Brazil from this [website](https://data.humdata.org/dataset/ourairports-bra), I will save it in my **data** folder:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f9nOcIOT4T0f"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "infoairports=pd.read_csv(os.path.join(\"data\",\"br-airports.csv\"))\n",
        "\n",
        "# some rows\n",
        "\n",
        "infoairports.iloc[[0,1,2,3,-4,-3,-2,-1],:] #head and tail"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JqVmiWVP4T0f"
      },
      "source": [
        "This needs some cleaning:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qQIDOlRF4T0f"
      },
      "outputs": [],
      "source": [
        "# bye first row\n",
        "infoairports.drop(index=0,inplace=True)\n",
        "infoairports.reset_index(drop=True, inplace=True)\n",
        "infoairports.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nUieBgAY4T0f"
      },
      "outputs": [],
      "source": [
        "# keep the  columns needed\n",
        "\n",
        "infoairports.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PS9LRMIZ4T0f"
      },
      "outputs": [],
      "source": [
        "keep=['name','type','latitude_deg', 'longitude_deg','elevation_ft','region_name','municipality']\n",
        "infoairports=infoairports.loc[:,keep]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Td2xMEj44T0f"
      },
      "outputs": [],
      "source": [
        "infoairports.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zNkPL-TS4T0f"
      },
      "source": [
        "Some formatting:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pilebl5g4T0g"
      },
      "outputs": [],
      "source": [
        "numericCols=['latitude_deg', 'longitude_deg','elevation_ft']\n",
        "infoairports[numericCols]=infoairports.loc[:,numericCols].apply(lambda x:pd.to_numeric(x))\n",
        "\n",
        "# now\n",
        "infoairports.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EdFkGoP-4T0g"
      },
      "outputs": [],
      "source": [
        "# let's plot\n",
        "\n",
        "base = brazil_5641.plot(color='white', edgecolor='black') #unprojected\n",
        "\n",
        "infoairports.plot.scatter(x = 'longitude_deg', y = 'latitude_deg',ax=base)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "unSG2UWS4T0g"
      },
      "source": [
        "Why is it wrong?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eikaZ5Fv4T0g"
      },
      "outputs": [],
      "source": [
        "airports=gpd.GeoDataFrame(data=infoairports.copy(),\n",
        "                 geometry=gpd.points_from_xy(infoairports.longitude_deg,\n",
        "                                             infoairports.latitude_deg),\n",
        "                 crs=brazil.crs.to_epsg())# the coordinates were in degrees - unprojected"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "06Iyhqwm4T0g"
      },
      "outputs": [],
      "source": [
        "# does it look better?\n",
        "\n",
        "# let's plot\n",
        "\n",
        "base = brazil_5641.plot(color='white', edgecolor='black')\n",
        "airports.plot(ax=base)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gYOATV2u4T0g"
      },
      "outputs": [],
      "source": [
        "#remember:\n",
        "type(airports), type(infoairports)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gRa8Tui44T0g"
      },
      "source": [
        "Let's keep the projected version:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s3h4wOc74T0g"
      },
      "outputs": [],
      "source": [
        "airports_5641=airports.to_crs(5641)\n",
        "\n",
        "## then\n",
        "\n",
        "base = brazil_5641.plot(color='white', edgecolor='black')\n",
        "airports_5641.plot(ax=base)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FDvn1kpj4T0g"
      },
      "source": [
        "Remember you have type of airports:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FWoIOU6G4T0h"
      },
      "outputs": [],
      "source": [
        "airports_5641['type'].value_counts() # this will not work: airports.type.value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yXVCSCNb4T0h"
      },
      "source": [
        "We may use that in the future. For now, just rename the **type** column to a different one."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TNq313AF4T0h"
      },
      "outputs": [],
      "source": [
        "airports_5641.rename(columns={'type':'kind'},inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oO9eHLNI4T0h"
      },
      "outputs": [],
      "source": [
        "# adding the airports\n",
        "airports_5641.to_file(os.path.join(\"maps\",\"brazilMaps_5641.gpkg\"), layer='airports', driver=\"GPKG\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jHzrZqzn4T0h"
      },
      "source": [
        "## Geo Merging\n",
        "\n",
        "Remember we have these data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rRALTV1a4T0h"
      },
      "outputs": [],
      "source": [
        "countries"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AB-QvNC54T0h"
      },
      "source": [
        "This map has no interesting information beyond the geometry. Let me bring this info:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mNThr6de4T0h"
      },
      "outputs": [],
      "source": [
        "fragilityLink=\"https://github.com/SocialAnalytics-StrategicIntelligence/TableOperations/raw/main/dataFiles/fragility/fragilityCoded_2012_2023.pkl\"\n",
        "\n",
        "fragility=pd.read_pickle(fragilityLink)\n",
        "\n",
        "fragility.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wFajqyKp4T0h"
      },
      "source": [
        "We want to add the fragility data into the map. That is the merging process.\n",
        "For that, we need a common column. The country names is the option."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nur1WP4a4T0h"
      },
      "outputs": [],
      "source": [
        "# to upper case.\n",
        "countries['COUNTRY']=countries.COUNTRY.str.upper()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NJUs0RmP4T0i"
      },
      "source": [
        "It is very unlikely the names are written the same. Verify:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "swKmZbfA4T0i"
      },
      "outputs": [],
      "source": [
        "onlyFragil=set(fragility.Country)- set(countries.COUNTRY)\n",
        "onlyMap=set(countries.COUNTRY)- set(fragility.Country)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PDJVhdx74T0i"
      },
      "source": [
        "Check here:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "we8hLcQf4T0i"
      },
      "outputs": [],
      "source": [
        "onlyFragil"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5kLlXMTT4T0i"
      },
      "outputs": [],
      "source": [
        "# and here\n",
        "onlyMap"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E3WBPLpW4T0i"
      },
      "source": [
        "## Fuzzy merging"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FS6ioeDI4T0i"
      },
      "source": [
        "Let's find similar names:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RySerO9L4T0i"
      },
      "outputs": [],
      "source": [
        "from thefuzz import process\n",
        "\n",
        "[(country, process.extractOne(country,onlyMap)) for country in sorted(onlyFragil)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EQEtccpn4T0i"
      },
      "outputs": [],
      "source": [
        "# subsetting\n",
        "[(country, process.extractOne(country,onlyMap)) for country in sorted(onlyFragil)\n",
        " if process.extractOne(country,onlyMap)[1]>=90]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aPb1AEEg4T0i"
      },
      "source": [
        "Preparing a _dict_ of changes:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PvlzpTBe4T0j"
      },
      "outputs": [],
      "source": [
        "# then:\n",
        "try1={country: process.extractOne(country,onlyMap)[0] for country in sorted(onlyFragil)\n",
        " if process.extractOne(country,onlyMap)[1]>=90}\n",
        "try1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jWp51uzP4T0j"
      },
      "source": [
        "Making changes and updating:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A5mhmO2X4T0j"
      },
      "outputs": [],
      "source": [
        "fragility.Country.replace(try1,inplace=True)\n",
        "\n",
        "# updating\n",
        "onlyFragil=set(fragility.Country)- set(countries.COUNTRY)\n",
        "onlyMap=set(countries.COUNTRY)- set(fragility.Country)\n",
        "\n",
        "# new matches\n",
        "[(country, process.extractOne(country,onlyMap)) for country in sorted(onlyFragil)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0S-RImTf4T0j"
      },
      "outputs": [],
      "source": [
        "# then:\n",
        "try2={country: process.extractOne(country,onlyMap)[0] for country in sorted(onlyFragil)\n",
        " if process.extractOne(country,onlyMap)[1]!=60}\n",
        "try2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nyBmr-fA4T0j"
      },
      "outputs": [],
      "source": [
        "# changing\n",
        "fragility.Country.replace(try2,inplace=True)\n",
        "\n",
        "# new update\n",
        "onlyFragil=set(fragility.Country)- set(countries.COUNTRY)\n",
        "onlyMap=set(countries.COUNTRY)- set(fragility.Country)\n",
        "\n",
        "# new matches\n",
        "[(country, process.extractOne(country,onlyMap)) for country in sorted(onlyFragil)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rvwf1Vxl4T0j"
      },
      "source": [
        "At this stage, we go manual:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xqir6aoP4T0j"
      },
      "outputs": [],
      "source": [
        "fragility.Country.replace({'ESWATINI': 'SWAZILAND'},inplace=True)\n",
        "\n",
        "#\n",
        "onlyFragil=set(fragility.Country)- set(countries.COUNTRY)\n",
        "onlyMap=set(countries.COUNTRY)- set(fragility.Country)\n",
        "\n",
        "#\n",
        "[(country, process.extractOne(country,onlyMap)) for country in sorted(onlyFragil)]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wU4E8WBX4T0j"
      },
      "source": [
        "We can not improve the situation.\n",
        "\n",
        "Now, when you merge a GDF with a DF, **the GDF has to be on the left**:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UC2eB5Ss4T0j"
      },
      "outputs": [],
      "source": [
        "theMapAndData=countries.merge(fragility,left_on='COUNTRY', right_on='Country')\n",
        "# here it is (new map):\n",
        "theMapAndData.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jfgkOPkz4T0k"
      },
      "source": [
        "# Choropleths\n",
        "\n",
        "We should plan how to color the polygons based on some variable:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t9ZAqS2o4T0k"
      },
      "outputs": [],
      "source": [
        "theMapAndData['Total_mnmx'].describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "73jGa1KM4T0k"
      },
      "outputs": [],
      "source": [
        "theMapAndData.boxplot(column=['Total_mnmx'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nYJb2nm44T0k"
      },
      "outputs": [],
      "source": [
        "theMapAndData['Total_mnmx'].hist()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kho-EXyZ4T0k"
      },
      "source": [
        "Let's see other possibilities to cut the data (instead of the amount of intervals presented in the histogram), but please install [**numba**](https://numba.readthedocs.io/en/stable/user/installing.html) before runing the next code; also make sure you have **pysal**, **mapclassify** and **numpy** installed:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wYq8xnNm4T0k"
      },
      "outputs": [],
      "source": [
        "pip show numba pysal mapclassify numpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GD1jeJ9h4T0k"
      },
      "outputs": [],
      "source": [
        "import mapclassify\n",
        "import numpy as np\n",
        "\n",
        "np.random.seed(12345) # so we all get the same results!\n",
        "\n",
        "# let's try 5 intervals\n",
        "K=5\n",
        "theVar=theMapAndData.Total_mnmx\n",
        "# same interval width, easy interpretation\n",
        "ei5 = mapclassify.EqualInterval(theVar, k=K)\n",
        "# same interval width based on standard deviation, easy - but not as the previous one, poor when high skewness\n",
        "msd = mapclassify.StdMean(theVar)\n",
        "# interval width varies, counts per interval are close, not easy to grasp, repeated values complicate cuts\n",
        "q5=mapclassify.Quantiles(theVar,k=K)\n",
        "\n",
        "# based on similarity, good for multimodal data\n",
        "mb5 = mapclassify.MaximumBreaks(theVar, k=K)\n",
        "# based on similarity, good for skewed data\n",
        "ht = mapclassify.HeadTailBreaks(theVar) # no K needed\n",
        "# based on similarity, optimizer\n",
        "fj5 = mapclassify.FisherJenks(theVar, k=K)\n",
        "# based on similarity, optimizer\n",
        "jc5 = mapclassify.JenksCaspall(theVar, k=K)\n",
        "# based on similarity, optimizer\n",
        "mp5 = mapclassify.MaxP(theVar, k=K)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g8J6DsR14T0k"
      },
      "source": [
        "How can we select the right classification?\n",
        "Let me use the the Absolute deviation around class median (ADCM) to make the comparisson:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "94W2Fy3o4T0k"
      },
      "outputs": [],
      "source": [
        "class5 = ei5,msd, q5,mb5,  ht, fj5, jc5, mp5\n",
        "# Collect ADCM for each classifier\n",
        "fits = np.array([ c.adcm for c in class5])\n",
        "# Convert ADCM scores to a DataFrame\n",
        "adcms = pd.DataFrame(fits)\n",
        "# Add classifier names\n",
        "adcms['classifier'] = [c.name for c in class5]\n",
        "# Add column names to the ADCM\n",
        "adcms.columns = ['ADCM', 'Classifier']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RMCeQpOu4T0k"
      },
      "source": [
        "Now, plot the **adcms**:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gU8ldLyv4T0k"
      },
      "outputs": [],
      "source": [
        "adcms.sort_values('ADCM').plot.barh(x='Classifier')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q0cmJ9li4T0l"
      },
      "source": [
        "Let's save the best three strategies:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r5Q4JIoQ4T0l"
      },
      "outputs": [],
      "source": [
        "theMapAndData.loc[:,'Total_ei5'] = ei5.yb\n",
        "theMapAndData.loc[:,'Total_fj5'] = fj5.yb\n",
        "theMapAndData.loc[:,'Total_jc5'] = jc5.yb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L6_XV0tQ4T0l"
      },
      "outputs": [],
      "source": [
        "# there you are\n",
        "theMapAndData.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XYMC9bfj4T0m"
      },
      "source": [
        "Let's check the mean of 'Total_mnmx' by the labels of the columns created (from '0' to '4')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fgCPc6x14T0m"
      },
      "outputs": [],
      "source": [
        "indexList=['Total_ei5','Total_fj5','Total_jc5']\n",
        "aggregator={'Total_mnmx': ['mean']}\n",
        "\n",
        "pd.concat([theMapAndData[['Total_mnmx',col]].groupby(col,as_index=False).agg(aggregator) for col in indexList],axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0heRhg-54T0m"
      },
      "source": [
        "Verify data types:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tPgjm6s_4T0n"
      },
      "outputs": [],
      "source": [
        "theMapAndData.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6K2Kt1of4T0n"
      },
      "source": [
        "Let me create a copy of those columns with new names:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jLeR0kry4T0n"
      },
      "outputs": [],
      "source": [
        "newColNames=[ name+\"_cat\" for name in indexList]\n",
        "\n",
        "theMapAndData[newColNames]=theMapAndData.loc[:,indexList]\n",
        "theMapAndData.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iH9POdhH4T0n"
      },
      "outputs": [],
      "source": [
        "# renaming\n",
        "newLabelsForLevels={0:\"0_Great\", 1:\"1_Good\", 2:\"2_Middle\", 3:\"3_Bad\", 4:\"4_Poor\"}\n",
        "\n",
        "theMapAndData[newColNames]=theMapAndData.loc[:,newColNames].replace(newLabelsForLevels)\n",
        "theMapAndData.drop(columns=['Country'],inplace=True)\n",
        "theMapAndData"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nMbacMuP4T0n"
      },
      "source": [
        "We are ready for a choropleth:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tgcdEoZF4T0n"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "f, ax = plt.subplots(1, figsize=(10, 10))\n",
        "theMapAndData.plot(column='Total_ei5', # variable to plot\n",
        "                   cmap='viridis', # set of colors\n",
        "                   categorical=True, # can be interpreted as category\n",
        "                   edgecolor='white', # border color\n",
        "                   linewidth=0., # width of border\n",
        "                   alpha=1, # level of transparency (0 is invisible)\n",
        "                   legend=True, # need a legend?\n",
        "                   # location of legend: 'best', 'upper right', 'upper left', 'lower left',\n",
        "                   # 'lower right', 'right', 'center left', 'center right',\n",
        "                   # 'lower center', 'upper center', 'center'\n",
        "                   legend_kwds={'loc':\"lower left\"},\n",
        "        ax=ax\n",
        "       )\n",
        "\n",
        "ax.set_axis_off()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VaNtRNv84T0n"
      },
      "outputs": [],
      "source": [
        "# alternatively:\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "f, ax = plt.subplots(1, figsize=(10, 10))\n",
        "theMapAndData.plot(column='Total_ei5_cat', # annotated\n",
        "        cmap='viridis',\n",
        "        categorical=True,\n",
        "        edgecolor='white',\n",
        "        linewidth=0.,\n",
        "        alpha=1,\n",
        "        legend=True,\n",
        "        legend_kwds={'loc':3},\n",
        "        ax=ax\n",
        "       )\n",
        "\n",
        "ax.set_axis_off()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "guKnkDDn4T0n"
      },
      "source": [
        "Once you know the ADCM, you can request the choropleth without creating a variable:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hT7zRhs84T0n"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "f, ax = plt.subplots(1, figsize=(10, 10))\n",
        "theMapAndData.plot(column='Total_mnmx',\n",
        "        cmap='viridis',\n",
        "                   scheme=\"equal_interval\",\n",
        "        edgecolor='white',\n",
        "        linewidth=0.,\n",
        "        alpha=0.75,\n",
        "        legend=True,\n",
        "        legend_kwds={'loc':3},\n",
        "        ax=ax\n",
        "       )\n",
        "\n",
        "ax.set_axis_off()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "epageIrm4T0n"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "f, ax = plt.subplots(1, figsize=(10, 10))\n",
        "theMapAndData.plot(column='Total_ei5_cat',\n",
        "        cmap='viridis',\n",
        "        categorical=True,\n",
        "        edgecolor='white',\n",
        "        linewidth=0.,\n",
        "        alpha=0.75,\n",
        "        legend=True,\n",
        "        legend_kwds={'loc':\"lower right\"},\n",
        "        ax=ax\n",
        "       )\n",
        "\n",
        "ax.set_axis_off()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IAeOzlDZ4T0n"
      },
      "source": [
        "Let's save our data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kN53O4h_4T0o"
      },
      "outputs": [],
      "source": [
        "theMapAndData.to_file(os.path.join(\"maps\",\"theMapAndData.gpkg\"), layer='fragility', driver=\"GPKG\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iXeXqSYI4T0o"
      },
      "source": [
        "<div class=\"alert alert-danger\">\n",
        "  <strong>CHALLENGE 1</strong>\n",
        "    <br> * Create a public repo named \"week2_spatial\" with its README file. (1 point)\n",
        "    <br> * Clone the repo to your computer. (1 point)\n",
        "    <br> * In the local repo in your computer, create a folder named \"data\". (1 point)\n",
        "    <br> * Get Three maps for the same country: the lines can be rivers, highways or similar; the points have to be airports; and the polygons  of the 2rd administrative division ('provinces' in Per, 'counties' in USA). Download those maps into the \"data\" folder. You can find airports here: https://ourairports.com/data/ (5 points)\n",
        "    <br> * Plot in one map the three layers of maps, including the code. (5 points)\n",
        "    <br> * Publish the three layer map. (3 points)\n",
        "    <br> * Update the README to offer a quick explanation, the data dictionary, and the link to the published map. (2 points)\n",
        "    <br> * Make sure the code is well organized (explanations, comments, no warnings, no python messages). (2 points)\n",
        "    \n",
        "</div>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VkFbhe4w4T0o"
      },
      "source": [
        "<div class=\"alert alert-danger\">\n",
        "  <strong>CHALLENGE 2</strong>\n",
        "    <br> * Create a public repo named week2_spatial with its README file. (1 point)\n",
        "    <br> * Clone the repo to your computer. (1 point)\n",
        "    <br> * In the local repo in your computer, create a folder named \"data\". (1 point)\n",
        "    <br> * Get for the provinces of Peru data for any variable of your concern, the variable has to be measured in several years (you need at least 3 measures if the measures were every 5 or 10 years, or 10 measures if taken yearly). (4 points)\n",
        "    <br> * Merge that data into the map of provinces of Peru. (3 points)\n",
        "    <br> * Plot two maps, one with the provinces that improved, and other with the ones that worsen, include the code. (3 points)\n",
        "    <br> * Publish the two maps. (3 points)\n",
        "    <br> * Update the README to offer a quick explanation, the data dictionary, and the link to the published map. (2 points)\n",
        "    <br> * Make sure the code is well organized (explanations, comments, no warnings, no python messages). (2 points)\n",
        "    \n",
        "</div>\n"
      ]
    }
  ],
  "metadata": {
    "anaconda-cloud": {
      "attach-environment": true,
      "summary": "test"
    },
    "colab": {
      "provenance": []
    },
    "hide_input": false,
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    },
    "toc-autonumbering": false
  },
  "nbformat": 4,
  "nbformat_minor": 0
}